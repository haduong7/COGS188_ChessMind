{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Shihua Yang\n",
    "- Zhiheng Wu\n",
    "- Ha Duong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This project focus on developing and comparing multiple AI approaches for playing chess, including traditional minimax with alpha-beta pruning, Monte Carlo Tree Search (MCTS), and neural network evaluation. The data used will consist of chess positions represented as board states, move sequences, and game results. We will implement and evaluate these different algorithms by measuring their performance through win rates, computational efficiency (nodes explored), and playing strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Chess has been a central challenge in AI since its inception. Early methods relied heavily on minimax search and hand-created evaluation functions<a name=\"1\"></a>[<sup>[1]</sup>](#1), eventually culminating in IBM's Deep Blue defeating world champion Garry Kasparov in 1997 <a name=\"2\"></a>[<sup>[2]</sup>](#2).The landscape of computer chess changed dramatically with the introduction of Monte Carlo Tree Search (MCTS) in 2006. MCTS offered several advantages over traditional minimax: it required no domain-specific evaluation functions, scaled well with available computation, and could be effectively combined with machine learning approaches. This laid the groundwork for DeepMind's AlphaZero in 2017[3]. This demonstrated that a neural network combined with MCTS can achieve superhuman performance through pure self-play, without any human knowledge beyond the rules of chess<a name=\"3\"></a>[<sup>[3]</sup>](#3). Recent work has focused on creating more efficient hybrid approaches. The Leela Chess Zero project demonstrated that open-source implementations could replicate AlphaZero's success and showed how neural networks could be effectively combined with traditional alpha-beta search<a name=\"4\"></a>[<sup>[4]</sup>](#4). The success of these different approaches has sparked interest in comparing their relative strengths and weaknesses in controlled environments, especially in resource-constrained situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The project addresses the problem of implementing and comparing multiple AI algorithms for playing chess. We specifically focus on three different methods: minimax with alpha-beta pruning, MCTS, and neural network evaluation. This problem is quantifiable through several well-defined metrics: \n",
    "\n",
    "(1) The strength measured by the rating derived from game outcomes\n",
    "\n",
    "(2) Computational efficiency measured in nodes explored per second and memory usage\n",
    "\n",
    "(3) Decision quality measured by tactical puzzle accuracy. \n",
    "\n",
    "The problem is measurable and replicable through automated game play and systematic testing against standardized positions. Our solution is ML-relevant as it includes both traditional AI search techniques and modern machine learning approaches, allowing for direct comparison of these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "1. Lichess Elite Database\n",
    "- Source: https://database.nikonoel.fr/\n",
    "- Format: PGN (Portable Game Notation)\n",
    "- Key variables: moves, results, player ratings, opening codes\n",
    "\n",
    "2. Chess Puzzles Dataset\n",
    "- Source: Lichess Puzzle Database\n",
    "- Size: ~100,000 tactical positions\n",
    "- Format: FEN (Forsyth–Edwards Notation) + solution moves\n",
    "- Used for: Testing tactical accuracy of different engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our project will implement and compare three distinct chess-playing approaches. \n",
    "\n",
    "First, we'll develop a traditional minimax algorithm with alpha-beta pruning, using bitboard representation for efficient move generation and incorporating standard chess heuristics (piece values, mobility, pawn structure, king safety). The search will be optimized with iterative deepening, starting from depth 4, and include move ordering and transposition tables.\n",
    "\n",
    "Second, we'll implement Monte Carlo Tree Search (MCTS) with the standard four phases (selection, expansion, simulation, backpropagation). The selection phase will use the UCT formula with an exploration constant of √2, while the simulation phase will employ simple heuristics for quick playouts.\n",
    "\n",
    "Third, we'll develop a neural network-based approach. For this model:\n",
    "\n",
    "Input Representation: Board state encoded as an 8x8x14 tensor (14 channels for piece types and colors), with metadata in FEN format\n",
    "Architecture: CNN backbone for capturing local patterns, with separate policy and value heads\n",
    "Training Pipeline: Self-play reinforcement learning using PPO, with rewards of +1 for wins, -1 for losses, and 0 for draws\n",
    "\n",
    "Implementation: \n",
    "- Libraries: PyTorch, `python-chess`.  \n",
    "- Data Pipeline: Generate self-play games and filter high-quality positions.  \n",
    "- Reproducibility: Code and weights on GitHub; Docker for dependencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "Answer: After the human champions of chess are defeated by AI, now chess players broadly use AI to train. Move by algorithms is regarded as the optimized move. So players use the match rate between their own move and the move by algorithms to determine whether they move correctly. Being inspired that, in this project we will also use the method, Top-1 Accuracy, to find the match rate between move by our algorithm and the move by top human expert, to evaluate the strength of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "Answer: When we grabbed data, we may take use of the record of top human experts to feed our algorithms. The algorithms are just machines which have extraordinary learning skills. Once the algorithms learn and imitate the styles of human experts, other professional players can play against our algorithms over and over again. Then, the human experts, whose records are used to train our model, will be easily defeated and be more behindhand in the world rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *We will take advantage of iMessage and all other social apps to communicate and collaborate to write codes instantly, ensuring that our project can progressed efficiently.*\n",
    "* *Although we want to keep an extraordinary efficiency, because we know we will certainly face difficulteis while doing the project, we have low expectations of the amount of time we have to spend on the project. So we will polish our project repeatedly.*\n",
    "* *We will catch up with the deadlines, and try our best to keep our schedule ahead of the deadlines to make sure we have margin of safety to correct mistakes when the the due of project is upcoming.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Timeline Proposal:\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/15  |  10 AM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic| \n",
    "| 2/19  |  10 AM |  Finish the project proposal (Respectively) | Discuss more ideas come up with recently| \n",
    "| 2/25  | 10 AM  | Search for datasets, Import & Wrangle Data, do some EDA (Ha)  | Check for problems arising during wrangling together   |\n",
    "| 3/3  | 10 AM  | Finalize wrangling/EDA; Begin programming for project (Shihua) | Looking into details of the programming and figure out the problems arising together |\n",
    "| 3/13  | 10 AM  | Complete analysis; Draft results/conclusion/discussion (Zhiheng)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#1): Thompson, T. (2023, August 31). History of AI in games – chess. modl.ai | AI Engine for Game Development. https://modl.ai/chess/#:~:text=Chess%20was%20core%20to%20AI,domain%20knowledge%20about%20the%20game<br>\n",
    "<a name=\"lorenznote\"></a>2.[^](#2): Wikipedia contributors. (2025, February 10). Deep Blue versus Garry Kasparov. Wikipedia. https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov<br>\n",
    "<a name=\"lorenznote\"></a>3.[^](#3): J. Scheiermann and W. Konen, \"AlphaZero-Inspired Game Learning: Faster Training by Using MCTS Only at Test Time,\" in IEEE Transactions on Games, vol. 15, no. 4, pp. 637-647, Dec. 2023, doi: 10.1109/TG.2022.3206733.<br>\n",
    "<a name=\"lorenznote\"></a>4.[^](#4): Wikipedia contributors. (2025a, February 8). Leela Chess Zero. Wikipedia. https://en.wikipedia.org/wiki/Leela_Chess_Zero<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
